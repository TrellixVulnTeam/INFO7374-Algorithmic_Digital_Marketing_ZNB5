# -*- coding: utf-8 -*-
"""FAISS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17U9B5TbsXNSZwpM1VqVKU05eV1-gVuO-
"""

import numpy as np
from numpy.linalg import norm
import pickle
from tqdm import tqdm, tqdm_notebook
import os
import tensorflow as tf
import time
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
import faiss
from matplotlib import pyplot as plt



#from google.colab import drive

# This will prompt for authorization.
#drive.mount('/content/drive')

# Defining 50 layer residual network : ResNet50 trained on million images, to get features for our dataset.
model = ResNet50(weights='imagenet', include_top=False,
                 input_shape=(224, 224, 3))

#Extracting features of images by including image path and model trained above
def extract_features(img_path, model):
    input_shape = (224, 224, 3)
    img = image.load_img(img_path, target_size=(
        input_shape[0], input_shape[1]))
    img_array = image.img_to_array(img)
    expanded_img_array = np.expand_dims(img_array, axis=0)
    preprocessed_img = preprocess_input(expanded_img_array)
    features = model.predict(preprocessed_img)
    flattened_features = features.flatten()
    normalized_features = flattened_features / norm(flattened_features)
    return normalized_features

#Trying to extract features for all type of image formats specified. We are getting numerical vectors for images.
extensions = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG']
def get_file_list(root_dir):
    file_list = []
    counter = 1
    for root, directories, filenames in os.walk(root_dir):
        for filename in filenames:
            if any(ext in filename for ext in extensions):
                file_list.append(os.path.join(root, filename))
                counter += 1
    return file_list
root_dir = '/images'
filenames = sorted(get_file_list(root_dir))

feature_list = []
for i in tqdm_notebook(range(len(filenames))):
    feature_list.append(extract_features(filenames[i], model))

len(feature_list)
# Number of images

features=np.array(feature_list)
features.shape
#Number of features = 100352 for 116 images

dimensions=features.shape[1]
db_vectors=features 
nlist = 5  # number of clusters
quantiser = faiss.IndexFlatL2(dimensions) #to assign the vectors to a particular cluster. This is index that uses the L2 distance metric 
index = faiss.IndexIVFFlat(quantiser, dimensions, nlist,   faiss.METRIC_L2) #defining index

print(index.is_trained)   # False
index.train(db_vectors)  # train on the database vectors
print(index.ntotal)   # 0
index.add(db_vectors)   # add the vectors and update the index
print(index.is_trained)  # True
print(index.ntotal)

nprobe = 2  # find 2 most similar clusters
n_query = 1  
k = 10  # return 3 nearest neighbours
np.random.seed(0)   
#Trying out a random images at 23rd position in images folder :
distances, indices = index.search(feature_list[23].reshape(1,-1), k)

distances

indices #Similiar images indices

feature_list[1].reshape(1,-1).shape

list_ind=indices.flatten().tolist()

list_ind

#Showing images
f, ax = plt.subplots(1, 10, figsize=(16, 8))
for i,j in enumerate(list_ind):
  ax[i].imshow(plt.imread(filenames[j]))
  ax[i].set_axis_off()

plt.show()
  #print(i)

# Building out function to implement FAISS :
def faiss_similarity(img,k):
  feature_list=extract_features('images/'+str(img), model)
  nprobe = 2  # find 2 most similar clusters
  n_query = 1  
  print(feature_list)
  #k = 10  # return 10 nearest neighbours
  np.random.seed(0)
  dimensions=len(feature_list)   
  query_vectors = np.random.random((n_query, dimensions)).astype('float32')
  distances, indices = index.search(feature_list.reshape(1,-1), k)
  list_ind=indices.flatten().tolist()
  # f, ax = plt.subplots(1, 10, figsize=(16, 8))
  # for i,j in enumerate(list_ind):
  #   ax[i].imshow(plt.imread(filenames[j]))
  #   ax[i].set_axis_off()
  # plt.show()
  names=[]
  for i,j in enumerate(list_ind):
    names.append(filenames[j])
  return names  

faiss_similarity('3615116_1.jpg')

faiss_similarity('3693318_0.jpg')